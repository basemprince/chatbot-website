{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b84cc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e068192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env\")\n",
    "\n",
    "# ðŸš€ Initialize FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # In production, replace with your domain\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "# ðŸ“¬ FastAPI schema\n",
    "class Message(BaseModel):\n",
    "    text: str\n",
    "\n",
    "# ðŸ’¬ Initialize the LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "# ðŸ§  Memory for ongoing conversations\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# ðŸ§¾ Prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful, knowledgeable assistant representing Basem Shaker â€” a Data Scientist and Machine Learning Engineer with expertise in statistical modeling, deep learning, and production-scale ML systems. You help visitors understand his background, projects, publications, and experience across industries like automotive, manufacturing, and edge ML. Be concise, professional, and technical when needed. If asked, guide users to his portfolio (basemshaker.com), GitHub (basem-shaker), or contact details\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "legacy_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "def chat_endpoint(msg: Message):\n",
    "    response = legacy_chain.invoke({\"input\":msg.text})\n",
    "    return response[\"text\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
