{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from pydantic import BaseModel\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068192c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in .env\")\n",
    "\n",
    "# Initialize FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"https://www.basemshaker.com\", \"http://127.0.0.1:5500\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "\n",
    "# FastAPI schema\n",
    "class Message(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "# Paths\n",
    "VECTORSTORE_PATH = \"faiss_index\"\n",
    "\n",
    "# Load or create vectorstore\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "if pathlib.Path(VECTORSTORE_PATH).exists():\n",
    "    vectorstore = FAISS.load_local(VECTORSTORE_PATH, embeddings, allow_dangerous_deserialization=True)\n",
    "else:\n",
    "    loader = WebBaseLoader(\n",
    "        [\n",
    "            \"https://www.basemshaker.com\",\n",
    "            \"https://www.basemshaker.com/pages/machine-learn.html\",\n",
    "            \"https://www.basemshaker.com/pages/robotics.html\",\n",
    "            \"https://www.basemshaker.com/pages/automation.html\",\n",
    "            \"https://www.basemshaker.com/pages/simulation.html\",\n",
    "            \"https://www.basemshaker.com/pages/design.html\",\n",
    "            \"https://www.basemshaker.com/pages/work-experience.html\",\n",
    "            \"https://www.basemshaker.com/pages/education-experience.html\",\n",
    "        ]\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "    split_docs = splitter.split_documents(docs)\n",
    "\n",
    "    vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "    vectorstore.save_local(VECTORSTORE_PATH)\n",
    "\n",
    "# Create retriever + QA chain\n",
    "retriever = vectorstore.as_retriever()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are Basem Shakerâ€™s assistant, not Basem Shaker himself, you're just his assistant. Use only the provided context to answer the user's question.\n",
    "\n",
    "Your responses must be:\n",
    "- Concise (2â€“4 sentences max unless asked to elaborate),\n",
    "- Direct (no generic introductions or repetition),\n",
    "- Base it on the retrieved content.\n",
    "\n",
    "Basem can go by the name \"Basem Shaker\" or \"basem\" or \"sam\"\n",
    "- If the question is about Basem Shaker, answer it directly. if it is about you, answer it as if you are Basem Shaker's assistant, not Basem Shaker himself.\n",
    "- If the answer is not found in the context or in this pre-prompt, reply with: â€œI couldn't find a specific answer to that based on the available content.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4.1-nano\", temperature=0.1, max_tokens=1000)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs={\"prompt\": prompt_template},\n",
    ")\n",
    "\n",
    "\n",
    "# FastAPI endpoint\n",
    "@app.post(\"/chat\")\n",
    "def chat_endpoint(msg: Message):\n",
    "    response = qa_chain.invoke(msg.text)\n",
    "    return response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1fadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain.invoke(\"what else?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¡ FastAPI endpoint\n",
    "@app.post(\"/chat\")\n",
    "def chat_endpoint(msg: Message):\n",
    "    response = qa_chain.invoke(msg.text)\n",
    "    return response[\"result\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
